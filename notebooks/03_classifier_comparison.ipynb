{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Classifier Comparison: SVM vs CNN Architectures\n",
                "\n",
                "Compare classification performance of different approaches on hyperspectral data:\n",
                "\n",
                "1. **SVM with RBF kernel** - Spectral-only baseline\n",
                "2. **1D-CNN** - Spectral feature learning\n",
                "3. **2D-CNN** - Spatial feature extraction\n",
                "4. **3D-CNN** - Joint spatial-spectral learning\n",
                "\n",
                "Focus areas:\n",
                "- Overall classification accuracy\n",
                "- Edge-case pixel performance\n",
                "- Training efficiency\n",
                "- Effect of local similarity features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "from tqdm import tqdm\n",
                "import time\n",
                "\n",
                "# PyTorch\n",
                "import torch\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "# Our modules\n",
                "from src.data import preprocess_pipeline\n",
                "from src.features import extract_patches, split_dataset\n",
                "from src.models import (\n",
                "    SVMClassifier, create_model,\n",
                "    train_neural_network, create_data_loaders, TrainingConfig,\n",
                "    compute_all_metrics, print_classification_report,\n",
                "    batch_inference_cnn\n",
                ")\n",
                "\n",
                "# MLflow\n",
                "import mlflow\n",
                "mlflow.set_tracking_uri('mlruns')\n",
                "mlflow.set_experiment('classifier_comparison')\n",
                "\n",
                "np.random.seed(42)\n",
                "torch.manual_seed(42)\n",
                "\n",
                "print(\"✓ Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "USE_REAL_DATA = False  # Set to True if Indian Pines is downloaded\n",
                "\n",
                "if USE_REAL_DATA:\n",
                "    from src.data import load_benchmark_dataset\n",
                "    cube = load_benchmark_dataset('indian_pines', 'data/external/indian_pines')\n",
                "    hsi_data = cube.data\n",
                "    ground_truth = cube.ground_truth\n",
                "    class_names = cube.class_names\n",
                "else:\n",
                "    # Generate realistic synthetic data\n",
                "    print(\"Generating synthetic HSI data...\")\n",
                "    \n",
                "    height, width, n_bands = 80, 80, 150\n",
                "    n_classes = 6\n",
                "    \n",
                "    # Create class-specific spectral signatures\n",
                "    wavelengths = np.linspace(400, 2500, n_bands)\n",
                "    class_spectra = np.zeros((n_classes, n_bands))\n",
                "    for c in range(n_classes):\n",
                "        peak_pos = 500 + c * 350\n",
                "        class_spectra[c] = np.exp(-((wavelengths - peak_pos) ** 2) / (250 ** 2))\n",
                "        class_spectra[c] += 0.25 * np.exp(-((wavelengths - (1600 + c * 80)) ** 2) / (120 ** 2))\n",
                "    \n",
                "    # Generate ground truth with spatial structure\n",
                "    ground_truth = np.zeros((height, width), dtype=np.int32)\n",
                "    for c in range(1, n_classes):\n",
                "        for _ in range(np.random.randint(3, 7)):\n",
                "            cr, cc = np.random.randint(8, height - 8), np.random.randint(8, width - 8)\n",
                "            radius = np.random.randint(4, 12)\n",
                "            for r in range(max(0, cr - radius), min(height, cr + radius)):\n",
                "                for col in range(max(0, cc - radius), min(width, cc + radius)):\n",
                "                    if ((r - cr) ** 2 + (col - cc) ** 2) < radius ** 2:\n",
                "                        ground_truth[r, col] = c\n",
                "    \n",
                "    # Generate HSI cube\n",
                "    hsi_data = np.zeros((height, width, n_bands), dtype=np.float32)\n",
                "    for c in range(n_classes):\n",
                "        mask = ground_truth == c\n",
                "        n_px = np.sum(mask)\n",
                "        if n_px > 0:\n",
                "            hsi_data[mask] = class_spectra[c if c > 0 else 1] + 0.12 * np.random.randn(n_px, n_bands)\n",
                "    \n",
                "    class_names = ['Background'] + [f'Class_{c}' for c in range(1, n_classes)]\n",
                "\n",
                "print(f\"Data shape: {hsi_data.shape}\")\n",
                "print(f\"Labeled samples: {np.sum(ground_truth > 0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocess\n",
                "result = preprocess_pipeline(\n",
                "    hsi_data,\n",
                "    remove_water=False,\n",
                "    reduce_dims='pca',\n",
                "    n_components=30,\n",
                "    normalize='minmax',\n",
                "    log_to_mlflow=False\n",
                ")\n",
                "processed_data = result['data']\n",
                "print(f\"Preprocessed shape: {processed_data.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract patches\n",
                "PATCH_SIZE = 5\n",
                "\n",
                "dataset = extract_patches(\n",
                "    processed_data,\n",
                "    ground_truth,\n",
                "    window_size=PATCH_SIZE,\n",
                "    include_background=False,\n",
                "    log_to_mlflow=False\n",
                ")\n",
                "\n",
                "# Split\n",
                "train_set, val_set, test_set = split_dataset(\n",
                "    dataset,\n",
                "    train_ratio=0.15,\n",
                "    val_ratio=0.1,\n",
                "    test_ratio=0.75,\n",
                "    stratify=True,\n",
                "    log_to_mlflow=False\n",
                ")\n",
                "\n",
                "n_bands = processed_data.shape[-1]\n",
                "n_classes = len(np.unique(train_set.labels))\n",
                "\n",
                "print(f\"Train: {train_set.n_samples}\")\n",
                "print(f\"Val: {val_set.n_samples}\")\n",
                "print(f\"Test: {test_set.n_samples}\")\n",
                "print(f\"Bands: {n_bands}, Classes: {n_classes}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Edge Pixel Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.ndimage import sobel\n",
                "\n",
                "# Detect edge pixels\n",
                "edge_x = sobel(ground_truth.astype(float), axis=0)\n",
                "edge_y = sobel(ground_truth.astype(float), axis=1)\n",
                "edge_magnitude = np.sqrt(edge_x**2 + edge_y**2)\n",
                "\n",
                "edge_mask = (edge_magnitude > 0) & (ground_truth > 0)\n",
                "interior_mask = (edge_magnitude == 0) & (ground_truth > 0)\n",
                "\n",
                "# Get masks for test set\n",
                "test_positions = test_set.positions\n",
                "test_edge_mask = np.array([edge_mask[r, c] for r, c in test_positions])\n",
                "test_interior_mask = np.array([interior_mask[r, c] for r, c in test_positions])\n",
                "\n",
                "print(f\"Test edge pixels: {np.sum(test_edge_mask)} ({100*np.mean(test_edge_mask):.1f}%)\")\n",
                "print(f\"Test interior pixels: {np.sum(test_interior_mask)} ({100*np.mean(test_interior_mask):.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train and Evaluate Classifiers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_classifier(y_true, y_pred, edge_mask, interior_mask, name):\n",
                "    \"\"\"Compute and display evaluation metrics.\"\"\"\n",
                "    metrics = compute_all_metrics(y_true, y_pred)\n",
                "    \n",
                "    edge_acc = np.mean(y_pred[edge_mask] == y_true[edge_mask]) if np.sum(edge_mask) > 0 else 0\n",
                "    interior_acc = np.mean(y_pred[interior_mask] == y_true[interior_mask]) if np.sum(interior_mask) > 0 else 0\n",
                "    \n",
                "    return {\n",
                "        'Model': name,\n",
                "        'OA': metrics['overall_accuracy'],\n",
                "        'AA': metrics['average_accuracy'],\n",
                "        'Kappa': metrics['kappa_coefficient'],\n",
                "        'Edge_Acc': edge_acc,\n",
                "        'Interior_Acc': interior_acc,\n",
                "        'Edge_Gap': interior_acc - edge_acc\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "training_times = {}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 SVM Classifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Training SVM...\")\n",
                "\n",
                "X_train = train_set.get_center_pixels()\n",
                "y_train = train_set.labels\n",
                "X_test = test_set.get_center_pixels()\n",
                "y_test = test_set.labels\n",
                "\n",
                "with mlflow.start_run(run_name='SVM_RBF'):\n",
                "    start_time = time.time()\n",
                "    \n",
                "    svm = SVMClassifier(kernel='rbf', C=10.0, gamma='scale')\n",
                "    svm.fit(X_train, y_train, log_to_mlflow=False)\n",
                "    \n",
                "    training_times['SVM'] = time.time() - start_time\n",
                "    \n",
                "    y_pred_svm = svm.predict(X_test)\n",
                "    \n",
                "    result = evaluate_classifier(y_test, y_pred_svm, test_edge_mask, test_interior_mask, 'SVM_RBF')\n",
                "    results.append(result)\n",
                "    \n",
                "    mlflow.log_params({'model': 'SVM', 'kernel': 'rbf', 'C': 10.0})\n",
                "    mlflow.log_metrics({k: v for k, v in result.items() if isinstance(v, float)})\n",
                "\n",
                "print(f\"SVM trained in {training_times['SVM']:.2f}s\")\n",
                "print(f\"OA: {result['OA']:.4f}, Edge: {result['Edge_Acc']:.4f}, Interior: {result['Interior_Acc']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 1D-CNN (Spectral)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nTraining 1D-CNN...\")\n",
                "\n",
                "# Create data loaders\n",
                "train_loader_1d = create_data_loaders(train_set.patches, train_set.labels, batch_size=32, data_format='1d')\n",
                "val_loader_1d = create_data_loaders(val_set.patches, val_set.labels, batch_size=32, shuffle=False, data_format='1d')\n",
                "\n",
                "# Create model\n",
                "model_1d = create_model('1d_cnn', n_bands=n_bands, n_classes=n_classes)\n",
                "\n",
                "# Training config\n",
                "config = TrainingConfig(\n",
                "    experiment_name='classifier_comparison',\n",
                "    run_name='1D_CNN',\n",
                "    n_epochs=30,\n",
                "    batch_size=32,\n",
                "    learning_rate=0.001,\n",
                "    patience=10,\n",
                "    device=device\n",
                ")\n",
                "\n",
                "start_time = time.time()\n",
                "model_1d, history_1d = train_neural_network(\n",
                "    model_1d, train_loader_1d, val_loader_1d,\n",
                "    config=config,\n",
                "    log_to_mlflow=True\n",
                ")\n",
                "training_times['1D_CNN'] = time.time() - start_time\n",
                "\n",
                "# Evaluate\n",
                "test_data_1d = test_set.get_center_pixels()\n",
                "y_pred_1d, _ = batch_inference_cnn(model_1d, test_data_1d, batch_size=64, device=device, data_format='1d')\n",
                "\n",
                "result = evaluate_classifier(y_test, y_pred_1d, test_edge_mask, test_interior_mask, '1D_CNN')\n",
                "results.append(result)\n",
                "\n",
                "print(f\"1D-CNN trained in {training_times['1D_CNN']:.2f}s\")\n",
                "print(f\"OA: {result['OA']:.4f}, Edge: {result['Edge_Acc']:.4f}, Interior: {result['Interior_Acc']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 2D-CNN (Spatial)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nTraining 2D-CNN...\")\n",
                "\n",
                "# Create data loaders\n",
                "train_loader_2d = create_data_loaders(train_set.patches, train_set.labels, batch_size=32, data_format='2d')\n",
                "val_loader_2d = create_data_loaders(val_set.patches, val_set.labels, batch_size=32, shuffle=False, data_format='2d')\n",
                "\n",
                "# Create model\n",
                "model_2d = create_model('2d_cnn', n_bands=n_bands, n_classes=n_classes, patch_size=PATCH_SIZE)\n",
                "\n",
                "config.run_name = '2D_CNN'\n",
                "\n",
                "start_time = time.time()\n",
                "model_2d, history_2d = train_neural_network(\n",
                "    model_2d, train_loader_2d, val_loader_2d,\n",
                "    config=config,\n",
                "    log_to_mlflow=True\n",
                ")\n",
                "training_times['2D_CNN'] = time.time() - start_time\n",
                "\n",
                "# Evaluate\n",
                "y_pred_2d, _ = batch_inference_cnn(model_2d, test_set.patches, batch_size=64, device=device, data_format='2d')\n",
                "\n",
                "result = evaluate_classifier(y_test, y_pred_2d, test_edge_mask, test_interior_mask, '2D_CNN')\n",
                "results.append(result)\n",
                "\n",
                "print(f\"2D-CNN trained in {training_times['2D_CNN']:.2f}s\")\n",
                "print(f\"OA: {result['OA']:.4f}, Edge: {result['Edge_Acc']:.4f}, Interior: {result['Interior_Acc']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.4 3D-CNN (Spatial-Spectral)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nTraining 3D-CNN...\")\n",
                "\n",
                "# Create data loaders\n",
                "train_loader_3d = create_data_loaders(train_set.patches, train_set.labels, batch_size=16, data_format='3d')\n",
                "val_loader_3d = create_data_loaders(val_set.patches, val_set.labels, batch_size=16, shuffle=False, data_format='3d')\n",
                "\n",
                "# Create model\n",
                "model_3d = create_model('3d_cnn', n_bands=n_bands, n_classes=n_classes, patch_size=PATCH_SIZE)\n",
                "\n",
                "config.run_name = '3D_CNN'\n",
                "config.batch_size = 16  # 3D CNNs need smaller batches\n",
                "\n",
                "start_time = time.time()\n",
                "model_3d, history_3d = train_neural_network(\n",
                "    model_3d, train_loader_3d, val_loader_3d,\n",
                "    config=config,\n",
                "    log_to_mlflow=True\n",
                ")\n",
                "training_times['3D_CNN'] = time.time() - start_time\n",
                "\n",
                "# Evaluate\n",
                "y_pred_3d, _ = batch_inference_cnn(model_3d, test_set.patches, batch_size=32, device=device, data_format='3d')\n",
                "\n",
                "result = evaluate_classifier(y_test, y_pred_3d, test_edge_mask, test_interior_mask, '3D_CNN')\n",
                "results.append(result)\n",
                "\n",
                "print(f\"3D-CNN trained in {training_times['3D_CNN']:.2f}s\")\n",
                "print(f\"OA: {result['OA']:.4f}, Edge: {result['Edge_Acc']:.4f}, Interior: {result['Interior_Acc']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Results Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create results DataFrame\n",
                "df_results = pd.DataFrame(results)\n",
                "\n",
                "# Add training times\n",
                "df_results['Train_Time_s'] = df_results['Model'].map(training_times)\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"CLASSIFIER COMPARISON RESULTS\")\n",
                "print(\"=\"*80)\n",
                "print(df_results.to_string(index=False, float_format='%.4f'))\n",
                "print(\"\\n\" + \"=\"*80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "models = df_results['Model'].tolist()\n",
                "x = np.arange(len(models))\n",
                "width = 0.35\n",
                "\n",
                "# Plot 1: Overall Accuracy\n",
                "axes[0].bar(x, df_results['OA'], width, label='OA', color='steelblue')\n",
                "axes[0].bar(x + width, df_results['AA'], width, label='AA', color='coral')\n",
                "axes[0].set_xlabel('Classifier')\n",
                "axes[0].set_ylabel('Accuracy')\n",
                "axes[0].set_title('Overall vs Average Accuracy')\n",
                "axes[0].set_xticks(x + width/2)\n",
                "axes[0].set_xticklabels(models, rotation=45, ha='right')\n",
                "axes[0].legend()\n",
                "axes[0].set_ylim(0, 1.1)\n",
                "\n",
                "# Plot 2: Edge vs Interior Accuracy\n",
                "axes[1].bar(x - width/2, df_results['Interior_Acc'], width, label='Interior', color='green')\n",
                "axes[1].bar(x + width/2, df_results['Edge_Acc'], width, label='Edge', color='red')\n",
                "axes[1].set_xlabel('Classifier')\n",
                "axes[1].set_ylabel('Accuracy')\n",
                "axes[1].set_title('Interior vs Edge Pixel Accuracy')\n",
                "axes[1].set_xticks(x)\n",
                "axes[1].set_xticklabels(models, rotation=45, ha='right')\n",
                "axes[1].legend()\n",
                "axes[1].set_ylim(0, 1.1)\n",
                "\n",
                "# Plot 3: Training Time\n",
                "axes[2].bar(x, df_results['Train_Time_s'], color='purple')\n",
                "axes[2].set_xlabel('Classifier')\n",
                "axes[2].set_ylabel('Training Time (s)')\n",
                "axes[2].set_title('Training Time Comparison')\n",
                "axes[2].set_xticks(x)\n",
                "axes[2].set_xticklabels(models, rotation=45, ha='right')\n",
                "\n",
                "plt.suptitle('Classifier Comparison on HSI Classification', fontsize=14, y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.savefig('classifier_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find best model\n",
                "best_model = df_results.loc[df_results['OA'].idxmax(), 'Model']\n",
                "best_edge_model = df_results.loc[df_results['Edge_Acc'].idxmax(), 'Model']\n",
                "\n",
                "print(f\"\\n★ Best Overall Accuracy: {best_model}\")\n",
                "print(f\"★ Best Edge Pixel Accuracy: {best_edge_model}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Thesis Conclusions\n",
                "\n",
                "### Key Findings\n",
                "\n",
                "1. **SVM vs CNN**: How do spectral-only methods compare to spatial-spectral methods?\n",
                "2. **Edge Pixels**: Which architecture handles boundary pixels best?\n",
                "3. **Efficiency**: Trade-off between accuracy and training time\n",
                "\n",
                "### Recommendations for Thesis\n",
                "\n",
                "- Use **SVM** as baseline for spectral-only classification\n",
                "- Compare **3D-CNN** for joint spatial-spectral feature learning\n",
                "- Report **edge pixel accuracy** as key metric for local similarity"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save results\n",
                "df_results.to_csv('classifier_comparison_results.csv', index=False)\n",
                "print(\"\\n✓ Results saved to classifier_comparison_results.csv\")\n",
                "print(\"\\nView all experiments in MLflow: mlflow ui --port 5000\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}