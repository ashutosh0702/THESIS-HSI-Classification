{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# σ Parameter Sensitivity Analysis for RBF Similarity\n",
    "\n",
    "This notebook analyzes how the **bandwidth parameter σ** in the RBF kernel affects:\n",
    "1. Local similarity structure within patches\n",
    "2. Classification accuracy\n",
    "3. Edge-case pixel performance\n",
    "\n",
    "## RBF Kernel Formula\n",
    "\n",
    "$$S(x_i, x_j) = \\exp\\left(-\\frac{\\|x_i - x_j\\|^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "- **Small σ**: Only very similar pixels have high similarity (local focus)\n",
    "- **Large σ**: Similarity decays slowly (global smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our modules\n",
    "from src.data import preprocess_pipeline\n",
    "from src.features import extract_patches, split_dataset\n",
    "from src.models import (\n",
    "    rbf_similarity, local_similarity_matrix, compute_local_similarity_features,\n",
    "    SVMClassifier, compute_all_metrics\n",
    ")\n",
    "\n",
    "# MLflow for tracking\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('mlruns')\n",
    "mlflow.set_experiment('sigma_sensitivity_analysis')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load or Generate Data\n",
    "\n",
    "Uncomment the appropriate section based on whether you have downloaded the benchmark datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_REAL_DATA = False  # Set to True if you have downloaded Indian Pines\n",
    "\n",
    "if USE_REAL_DATA:\n",
    "    # Load Indian Pines dataset\n",
    "    from src.data import load_benchmark_dataset\n",
    "    cube = load_benchmark_dataset('indian_pines', 'data/external/indian_pines')\n",
    "    hsi_data = cube.data\n",
    "    ground_truth = cube.ground_truth\n",
    "    class_names = cube.class_names\n",
    "    print(f\"Loaded Indian Pines: {hsi_data.shape}\")\n",
    "else:\n",
    "    # Generate realistic synthetic data with spectral structure\n",
    "    print(\"Generating synthetic HSI data with spectral structure...\")\n",
    "    \n",
    "    height, width, n_bands = 100, 100, 200\n",
    "    n_classes = 6\n",
    "    \n",
    "    # Create class-specific spectral signatures (more realistic)\n",
    "    # Each class has a base spectrum + class-specific variations\n",
    "    wavelengths = np.linspace(400, 2500, n_bands)\n",
    "    \n",
    "    # Base spectral patterns\n",
    "    class_spectra = np.zeros((n_classes, n_bands))\n",
    "    for c in range(n_classes):\n",
    "        # Each class has peaks at different wavelengths\n",
    "        peak_pos = 500 + c * 300  # Vary peak position by class\n",
    "        class_spectra[c] = np.exp(-((wavelengths - peak_pos) ** 2) / (200 ** 2))\n",
    "        # Add some secondary features\n",
    "        class_spectra[c] += 0.3 * np.exp(-((wavelengths - (1500 + c * 100)) ** 2) / (100 ** 2))\n",
    "    \n",
    "    # Generate ground truth with spatial structure (clustered classes)\n",
    "    ground_truth = np.zeros((height, width), dtype=np.int32)\n",
    "    \n",
    "    # Create regions for each class\n",
    "    for c in range(1, n_classes):\n",
    "        # Create random blobs for each class\n",
    "        n_blobs = np.random.randint(3, 8)\n",
    "        for _ in range(n_blobs):\n",
    "            center_r = np.random.randint(5, height - 5)\n",
    "            center_c = np.random.randint(5, width - 5)\n",
    "            radius = np.random.randint(3, 10)\n",
    "            \n",
    "            for r in range(max(0, center_r - radius), min(height, center_r + radius)):\n",
    "                for col in range(max(0, center_c - radius), min(width, center_c + radius)):\n",
    "                    if ((r - center_r) ** 2 + (col - center_c) ** 2) < radius ** 2:\n",
    "                        ground_truth[r, col] = c\n",
    "    \n",
    "    # Generate HSI cube based on ground truth with noise\n",
    "    hsi_data = np.zeros((height, width, n_bands), dtype=np.float32)\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        mask = ground_truth == c\n",
    "        n_pixels = np.sum(mask)\n",
    "        if n_pixels > 0:\n",
    "            # Add spectral signature with intra-class variation\n",
    "            base = class_spectra[c if c > 0 else 1]  # Use class 1 for background\n",
    "            noise = 0.1 * np.random.randn(n_pixels, n_bands)\n",
    "            hsi_data[mask] = base + noise\n",
    "    \n",
    "    class_names = ['Background'] + [f'Class_{c}' for c in range(1, n_classes)]\n",
    "    print(f\"Generated synthetic data: {hsi_data.shape}\")\n",
    "\n",
    "print(f\"Ground truth classes: {np.unique(ground_truth)}\")\n",
    "print(f\"Labeled samples: {np.sum(ground_truth > 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "result = preprocess_pipeline(\n",
    "    hsi_data,\n",
    "    remove_water=False,  # Already corrected for benchmark data\n",
    "    reduce_dims='pca',\n",
    "    n_components=30,     # Reduce to 30 PCA components\n",
    "    normalize='minmax',\n",
    "    log_to_mlflow=False\n",
    ")\n",
    "\n",
    "processed_data = result['data']\n",
    "print(f\"Preprocessed shape: {processed_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Sigma's Effect on Local Similarity\n",
    "\n",
    "Visualize how different σ values affect the similarity structure within a patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a sample patch\n",
    "window_size = 7\n",
    "half = window_size // 2\n",
    "\n",
    "# Find a labeled pixel near class boundaries (interesting case)\n",
    "labeled_positions = np.argwhere(ground_truth > 0)\n",
    "sample_pos = labeled_positions[len(labeled_positions) // 2]\n",
    "r, c = sample_pos\n",
    "\n",
    "# Extract patch\n",
    "padded = np.pad(processed_data, [(half, half), (half, half), (0, 0)], mode='reflect')\n",
    "sample_patch = padded[r:r + window_size, c:c + window_size, :]\n",
    "\n",
    "print(f\"Sample patch from position ({r}, {c})\")\n",
    "print(f\"Patch shape: {sample_patch.shape}\")\n",
    "print(f\"Center pixel class: {ground_truth[r, c]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze similarity matrix for different sigma values\n",
    "sigma_values = [0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.0, 5.0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, sigma in enumerate(sigma_values):\n",
    "    sim_matrix = local_similarity_matrix(sample_patch, metric='rbf', sigma=sigma)\n",
    "    \n",
    "    im = axes[i].imshow(sim_matrix, cmap='hot', vmin=0, vmax=1)\n",
    "    axes[i].set_title(f'σ = {sigma}\\nmean={np.mean(sim_matrix):.3f}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('RBF Similarity Matrix vs σ (Local Patch)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add colorbar\n",
    "fig.colorbar(im, ax=axes, shrink=0.8, label='Similarity')\n",
    "plt.savefig('sigma_similarity_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Small σ creates sparse similarity (only very close spectra match),\")\n",
    "print(\"while large σ creates dense similarity (everything looks similar).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. σ Sensitivity on Classification Accuracy\n",
    "\n",
    "Systematically test how σ affects SVM classification with RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches for classification\n",
    "patch_size = 5\n",
    "dataset = extract_patches(\n",
    "    processed_data,\n",
    "    ground_truth,\n",
    "    window_size=patch_size,\n",
    "    include_background=False,\n",
    "    log_to_mlflow=False\n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "train_set, val_set, test_set = split_dataset(\n",
    "    dataset,\n",
    "    train_ratio=0.2,  # Use 20% for training (realistic for HSI)\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.7,\n",
    "    stratify=True,\n",
    "    log_to_mlflow=False\n",
    ")\n",
    "\n",
    "# Get center pixels for SVM\n",
    "X_train = train_set.get_center_pixels()\n",
    "y_train = train_set.labels\n",
    "X_test = test_set.get_center_pixels()\n",
    "y_test = test_set.labels\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sensitivity analysis\n",
    "sigma_test_values = [0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Running σ sensitivity analysis...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for sigma in tqdm(sigma_test_values, desc=\"Testing σ values\"):\n",
    "    with mlflow.start_run(run_name=f'SVM_sigma_{sigma}'):\n",
    "        # Log parameters\n",
    "        mlflow.log_params({\n",
    "            'sigma': sigma,\n",
    "            'kernel': 'rbf',\n",
    "            'C': 10.0,\n",
    "            'patch_size': patch_size,\n",
    "            'train_samples': len(X_train),\n",
    "            'test_samples': len(X_test)\n",
    "        })\n",
    "        \n",
    "        # Train SVM with specific gamma (gamma = 1 / (2 * sigma^2))\n",
    "        gamma = 1.0 / (2 * sigma ** 2)\n",
    "        \n",
    "        svm = SVMClassifier(kernel='rbf', C=10.0, gamma=gamma)\n",
    "        svm.fit(X_train, y_train, log_to_mlflow=False)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = svm.predict(X_test)\n",
    "        metrics = compute_all_metrics(y_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            'overall_accuracy': metrics['overall_accuracy'],\n",
    "            'average_accuracy': metrics['average_accuracy'],\n",
    "            'kappa': metrics['kappa_coefficient']\n",
    "        })\n",
    "        \n",
    "        results.append({\n",
    "            'sigma': sigma,\n",
    "            'gamma': gamma,\n",
    "            'OA': metrics['overall_accuracy'],\n",
    "            'AA': metrics['average_accuracy'],\n",
    "            'Kappa': metrics['kappa_coefficient']\n",
    "        })\n",
    "        \n",
    "print(\"-\" * 60)\n",
    "print(\"Analysis complete! View in MLflow UI: mlflow ui --port 5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\nσ Sensitivity Results:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Find best sigma\n",
    "best_idx = df['OA'].idxmax()\n",
    "best_sigma = df.loc[best_idx, 'sigma']\n",
    "best_oa = df.loc[best_idx, 'OA']\n",
    "print(f\"\\n★ Best σ = {best_sigma} with OA = {best_oa:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sensitivity curve\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "metrics_to_plot = ['OA', 'AA', 'Kappa']\n",
    "titles = ['Overall Accuracy', 'Average Accuracy', 'Kappa Coefficient']\n",
    "\n",
    "for ax, metric, title in zip(axes, metrics_to_plot, titles):\n",
    "    ax.semilogx(df['sigma'], df[metric], 'o-', linewidth=2, markersize=8)\n",
    "    ax.axvline(x=best_sigma, color='r', linestyle='--', alpha=0.7, label=f'Best σ={best_sigma}')\n",
    "    ax.set_xlabel('σ (log scale)')\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_title(f'{title} vs σ')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('RBF Kernel σ Sensitivity Analysis', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sigma_sensitivity_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Edge Case Analysis\n",
    "\n",
    "Analyze how σ affects classification of \"mixed pixels\" near class boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find edge pixels (pixels adjacent to different classes)\n",
    "from scipy.ndimage import sobel\n",
    "\n",
    "# Compute gradient magnitude on ground truth to find edges\n",
    "edge_x = sobel(ground_truth.astype(float), axis=0)\n",
    "edge_y = sobel(ground_truth.astype(float), axis=1)\n",
    "edge_magnitude = np.sqrt(edge_x**2 + edge_y**2)\n",
    "\n",
    "# Edge pixels are where gradient is non-zero and there's a label\n",
    "edge_mask = (edge_magnitude > 0) & (ground_truth > 0)\n",
    "interior_mask = (edge_magnitude == 0) & (ground_truth > 0)\n",
    "\n",
    "print(f\"Edge pixels: {np.sum(edge_mask)}\")\n",
    "print(f\"Interior pixels: {np.sum(interior_mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze edge vs interior accuracy for different sigma\n",
    "# Get test set positions\n",
    "test_positions = test_set.positions\n",
    "\n",
    "edge_acc_per_sigma = []\n",
    "interior_acc_per_sigma = []\n",
    "\n",
    "for sigma in tqdm(sigma_test_values, desc=\"Edge analysis\"):\n",
    "    gamma = 1.0 / (2 * sigma ** 2)\n",
    "    \n",
    "    svm = SVMClassifier(kernel='rbf', C=10.0, gamma=gamma)\n",
    "    svm.fit(X_train, y_train, log_to_mlflow=False)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Classify test samples as edge or interior\n",
    "    test_edge_mask = np.array([edge_mask[r, c] for r, c in test_positions])\n",
    "    test_interior_mask = np.array([interior_mask[r, c] for r, c in test_positions])\n",
    "    \n",
    "    # Compute accuracy for each group\n",
    "    if np.sum(test_edge_mask) > 0:\n",
    "        edge_acc = np.mean(y_pred[test_edge_mask] == y_test[test_edge_mask])\n",
    "    else:\n",
    "        edge_acc = 0\n",
    "    \n",
    "    if np.sum(test_interior_mask) > 0:\n",
    "        interior_acc = np.mean(y_pred[test_interior_mask] == y_test[test_interior_mask])\n",
    "    else:\n",
    "        interior_acc = 0\n",
    "    \n",
    "    edge_acc_per_sigma.append(edge_acc)\n",
    "    interior_acc_per_sigma.append(interior_acc)\n",
    "\n",
    "print(\"\\nEdge vs Interior Accuracy:\")\n",
    "for sigma, edge_acc, int_acc in zip(sigma_test_values, edge_acc_per_sigma, interior_acc_per_sigma):\n",
    "    print(f\"σ={sigma:6.3f}  Edge: {edge_acc:.4f}  Interior: {int_acc:.4f}  Gap: {int_acc - edge_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot edge vs interior accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.semilogx(sigma_test_values, interior_acc_per_sigma, 'g-o', label='Interior Pixels', linewidth=2, markersize=8)\n",
    "ax.semilogx(sigma_test_values, edge_acc_per_sigma, 'r-s', label='Edge Pixels', linewidth=2, markersize=8)\n",
    "ax.fill_between(sigma_test_values, edge_acc_per_sigma, interior_acc_per_sigma, alpha=0.2, color='gray')\n",
    "\n",
    "ax.axvline(x=best_sigma, color='blue', linestyle='--', alpha=0.7, label=f'Best σ={best_sigma}')\n",
    "\n",
    "ax.set_xlabel('σ (log scale)', fontsize=12)\n",
    "ax.set_ylabel('Accuracy', fontsize=12)\n",
    "ax.set_title('Edge vs Interior Pixel Classification Accuracy', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.savefig('edge_interior_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n★ Key Finding: Edge pixels are harder to classify. The gap between\")\n",
    "print(\"  interior and edge accuracy varies with σ - this is important for thesis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Optimal σ range**: Based on the analysis, the best σ for this data is around X\n",
    "2. **Edge pixel sensitivity**: σ significantly affects edge pixel accuracy\n",
    "3. **Trade-off**: Small σ → local precision, Large σ → global smoothness\n",
    "\n",
    "### Thesis Implications\n",
    "\n",
    "- Document the optimal σ range for different datasets\n",
    "- Use edge pixel accuracy as a key metric for local similarity evaluation\n",
    "- Consider adaptive σ based on local spectral variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary for thesis\n",
    "summary = f\"\"\"\n",
    "========================================\n",
    "σ SENSITIVITY ANALYSIS SUMMARY\n",
    "========================================\n",
    "\n",
    "Dataset: {'Indian Pines' if USE_REAL_DATA else 'Synthetic'}\n",
    "Patch size: {patch_size}x{patch_size}\n",
    "Training samples: {len(X_train)}\n",
    "Test samples: {len(X_test)}\n",
    "\n",
    "Best σ: {best_sigma}\n",
    "Best Overall Accuracy: {best_oa:.4f}\n",
    "\n",
    "Edge Pixel Analysis:\n",
    "- Edge pixels: {np.sum(test_edge_mask)} ({100*np.sum(test_edge_mask)/len(y_test):.1f}% of test)\n",
    "- Interior pixels: {np.sum(test_interior_mask)} ({100*np.sum(test_interior_mask)/len(y_test):.1f}% of test)\n",
    "\n",
    "σ Sensitivity Table:\n",
    "{df.to_string(index=False)}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save to file\n",
    "with open('sigma_analysis_summary.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "print(\"\\n✓ Summary saved to sigma_analysis_summary.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
